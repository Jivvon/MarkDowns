# 201502119 정지원 lab08 보고서

### 데이터 전처리

##### 단어사전 만들기

```python
def make_vocab(vocab_path, train=None):
    vocab = {}
    if os.path.isfile(vocab_path):...
    else:...
            sentence = data['Phrase'].lower() # 소문자
            tokens = sentence.split(' ')
            for token in tokens: # 토큰을 넣는다.
                count_dict[token] += 1

        file = open(vocab_path, 'w', encoding = 'utf-8')
				# 0은 unknown 토큰 : train에서는 나오고 test에서는 나오는 경우
        # 1은 padding 토큰 : max보다 작은 문장에 빈 공간을 채워넣음
        file.write('[UNK]\t0\n[PAD]\t1\n') 
        vocab = {'[UNK]' : 0, '[PAD]' : 1}

        for index, (token, count) in enumerate(sorted(count_dict.items(), reverse=True, key=lambda item: item[1])):
            vocab[token] = index + 2 # 0 : unknown 토큰, 1 : padding 토큰 이므로 +2
            file.write(token + '\t' + str(index + 2) + '\n')
        file.close()

    return vocab
```

데이터를 읽어 소문자로 바꾼 후, 공백을 기준으로 분리한 데이터를 가지고 단어사전을 만든다. 이 때 만든 단어사전을 활용하여 각 단어를 숫자로 바꾼다.

##### 데이터 읽기

```python
def read_data(train, test, vocab, max_len):
    x_train = np.ones(shape=(len(train), max_len)) # padding 토큰(1)로 초기화하고 시작한다
    for i, data in tqdm(enumerate(train['Phrase']), desc='make x_train data', total=len(train)):
        data = data.lower() # 소문자
        tokens = data.split(' ')
        for j, token in enumerate(tokens):
            if j == max_len: # 최대 길이가 넘어가면 자른다
                break
            x_train[i][j] = vocab[token]

    x_test = np.ones(shape=(len(test), max_len))
    ... # test도 train과 똑같이
            if token not in vocab.keys(): # train 데이터에 없던 단어는 unknown으로 처리한다
                x_test[i][j] = 0
            else:
                x_test[i][j] = vocab[token]

    y_train = train['Sentiment'].to_numpy()
    return x_train, y_train, x_test
```

최대 길이(50)이 넘어가면 예측하는데 도움이 안 되기 때문에 그냥 자른다.

train 데이터에 없던 단어가 나오면 unknown(0)으로 처리한다.

즉, 모든 토큰을 padding으로 채운 후, train에서 본 단어가 나오면 해당 토큰을 넣고, train에서 못 본 단어가 나오면 unknown으로 처리하여 데이터를 읽는다.



#### RNN Model

```python
class RNN(nn.Module):
    # input size : vocab 개수
    # output_size : label 5개
    # bidirect : 양방향 기능
    # num_layers : hidden (은닉층)
    def __init__(self, input_size, embed_size, hidden_size, output_size, num_layers=1, bidirec=True, device='cuda'):
        ...# hidden size와 num layer 설정
        ...# RNN은 양방향을 사용할 수 있다.
        self.embed = nn.Embedding(input_size, embed_size, padding_idx = 1) # padding token은 1번
        ...# lstm 만든다
        ...# lstm에서 나온 정보를 output_size로 축소 (추상화)

    ...# lstm은 0으로 초기화해준다. to 는 GPU vs CPU 뭘 사용할 것인지.
      
    def forward(self, inputs):
      	...
        hidden = hidden[-self.num_directions:]# Many to One
        ...
        return output
```

RNN의 코드가 길어 주석을 제외하고 코드를 제거하였다.



RNN 모델은 양방향으로 데이터를 고려할 수 있는데, 양방향과 단방향 둘 다 해본 결과, 양방향이 성능이 아주 조금 더 좋게 나와서 양방향 옵션(bidirec)을 True로 하였다.



<img src="/Users/jiwon/Library/Application Support/typora-user-images/스크린샷 2020-05-17 오후 11.32.41.png" alt="스크린샷 2020-05-17 오후 11.32.41" style="zoom:50%;" />

강의 ppt에 있는 many to one이 forward 함수의 hidden을 처리하는 부분에 해당한다.



### train

```python
def train(x, y, max_len, embed_size, hidden_size, output_size, batch_size, epochs, lr, device, model=None):
    x = torch.from_numpy(x).long()
    y = torch.from_numpy(y).long()
    if model is None:
        model = RNN(max_len, embed_size, hidden_size, output_size, device=device)
    model.to(device)
    model.train()
    loss_function = nn.CrossEntropyLoss() # One-Hot Encoding 해줌
    optimizer = optim.Adam(model.parameters(), lr=lr) # 학습 반영
```

미리 만들어 놓은 RNN 모델을 불러오고, 손실율을 구하는 함수, 결과 방법(Adam)을 정의해준다.

```python
data_loader = torch.utils.data.DataLoader(list(zip(x,y)), batch_size, shuffle=True) # 데이터 잘라서 섞기
```

DataLoader를 통해 데이터를 불러오는데, batch 사이즈만큼 나누어 처리한다.

정확도를 높이기 위해 zip(x,y) : x와 y를 묶어 shffle=True 섞는다.

```python
for epoch in trange(epochs):
        epoch_loss = 0
        epoch_acc = 0
        for batch_data in data_loader:
            x_batch, y_batch = batch_data
            x_batch = x_batch.to(device) # to : gpu 사용. (data와 test 둘 다 같은 걸로 해야한다)
            y_batch = y_batch.to(device) #

            # 아래의 3단계를 통해 가중치와 편향값을 보정한다.
            # forward : 모델을 통해 예측한다.
            pred = model(x_batch)

            # backward 채점 및 학습 : 예측한 결과를 답과 비교 후 학습한다.
            loss = loss_function(pred, y_batch)
            optimizer.zero_grad() # zero gradients
            loss.backward()

            # update 학습 반영 : 학습된 결과를 반영한다.
            optimizer.step()

            epoch_loss += loss.item()
            epoch_acc += get_acc(pred, y_batch)
        epoch_loss /= len(data_loader)
        epoch_acc /= len(data_loader)
        loss_total.append(epoch_loss)
        acc_total.append(epoch_acc)
```

epoch(10)만큼 데이터 전체를 학습한다.

model(x_batch) [**forward**] : 손실값과 정확도를 측정하는데, data_loader에서 불러왔던 데이터를 모델을 통해 학습한다

loss_function(...)~backward() [**backward**] : 이후 loss 함수를 통해 예측한 결과와 답을 비교 후 학습한다.

optimizer.step() : 마지막으로, 학습된 결과를 반영한다.

##### 정확도는 학습된 결과가 답을 맞춘 비율로 구하였다.

<img src="/Users/jiwon/Library/Application Support/typora-user-images/스크린샷 2020-05-17 오후 11.14.49.png" alt="스크린샷 2020-05-17 오후 11.14.49" style="zoom:50%;" />

### test

##### 학습된 모델을 가지고 test데이터를 예측한다.

```python
def test(model, x, batch_size, device):
    model.to(device)
    model.eval()
    x = torch.from_numpy(x).long()
    data_loader = torch.utils.data.DataLoader(x, batch_size, shuffle=False)

    predict = []
    for batch_data in data_loader:
        batch_data = batch_data.to(device)
        pred = model(batch_data)
        for p in pred:
            pv, pi = p.max(0)
            predict.append(pi.item())

    return predict
```


train 데이터와 마찬가지도 DataLoader를 통해 데이터를 불러오는데, 이 때 test 데이터는 평가하는 데이터이므로 shuffle을 사용하지 않고, shuffle을 사용하지 않으므로 x와 y를 묶을 (zip) 필요가 없다.

test 데이터를 학습된 모델을 통해 예측한다.



---

### 결과

<div style="display:flex;flex-flow:row nowrap;justify-content:space-around;">
	<div>
<img src="/Users/jiwon/Library/Application Support/typora-user-images/스크린샷 2020-05-17 오후 11.16.00.png" alt="스크린샷 2020-05-17 오후 11.16.00" style="zoom:80%;" />
	</div>  
	<div>
<img src="/Users/jiwon/Library/Application Support/typora-user-images/스크린샷 2020-05-17 오후 11.16.11.png" alt="스크린샷 2020-05-17 오후 11.16.11" style="zoom:80%;" />
	</div>
</div>
위는 에폭의 반복에 따라 각각 Loss값과 정확도를 표현한 그래프이다.

<div>
<img src="/Users/jiwon/Library/Application Support/typora-user-images/스크린샷 2020-05-17 오후 11.18.50.png" alt="스크린샷 2020-05-17 오후 11.18.50" style="zoom:40%;" />
<div>위 그래프의 정확한 수치는 다음과 같다</div>
</div>


##### 실행결과

RNN 모델에서 양방향으로 고려하는 경우가 더 좋은 결과가 나와서 이를 사용하여 제출하였다.

![스크린샷 2020-05-17 오후 11.17.07](/Users/jiwon/Library/Application Support/typora-user-images/스크린샷 2020-05-17 오후 11.17.07.png)