# 201502119 정지원 lab07 보고서

### 데이터 전처리

<img src="/Users/jiwon/Library/Application Support/typora-user-images/스크린샷 2020-05-06 오후 1.59.55.png" alt="스크린샷 2020-05-06 오후 1.59.55" style="zoom:80%;" />

데이터를 불러와 train 데이터와 test 데이터 모두 0~1 범위로 만든다. 



#### MNISTModel

<img src="/Users/jiwon/Library/Application Support/typora-user-images/스크린샷 2020-05-06 오후 7.37.25.png" alt="스크린샷 2020-05-06 오후 7.37.25" style="zoom:80%;" />

<img src="/Users/jiwon/Library/Application Support/typora-user-images/스크린샷 2020-05-06 오후 7.38.02.png" alt="스크린샷 2020-05-06 오후 7.38.02" style="zoom:80%;" />

강의에서 활용된 ppt에 있는 내용을 그대로 784에서 512, 512에서 10으로 classification한다.



### train

##### Mnist 모델을 만들어 train 데이터로 학습시킨다.



![스크린샷 2020-05-06 오후 8.09.18](/Users/jiwon/Library/Application Support/typora-user-images/스크린샷 2020-05-06 오후 8.09.18.png)

Mnist 모델을 만들고, 손실율을 구하는 함수, 결과 방법(Adam)을 정의해준다.



![스크린샷 2020-05-06 오후 7.50.02](/Users/jiwon/Library/Application Support/typora-user-images/스크린샷 2020-05-06 오후 7.50.02.png)

DataLoader를 통해 데이터를 불러오는데, batch 사이즈만큼(128) 나누어 처리한다.

정확도를 높이기 위해 zip(x,y) : x와 y를 묶어 shffle=True 섞는다.



![스크린샷 2020-05-06 오후 7.57.42](/Users/jiwon/Library/Application Support/typora-user-images/스크린샷 2020-05-06 오후 7.57.42.png)

epoch(10)만큼 데이터 전체를 학습한다.

model(x_batch) [**forward**] : 손실값과 정확도를 측정하는데, data_loader에서 불러왔던 데이터를 모델을 통해 학습한다

loss_function(...)~backward() [**backward**] : 이후 loss 함수를 통해 예측한 결과와 답을 비교 후 학습한다.

optimizer.step() : 마지막으로, 학습된 결과를 반영한다.

##### 정확도는 학습된 결과가 답을 맞춘 비율로 구하였다.

![스크린샷 2020-05-06 오후 8.05.41](/Users/jiwon/Library/Application Support/typora-user-images/스크린샷 2020-05-06 오후 8.05.41.png)

<div class="page-break"></div>

### test

##### 학습된 모델을 가지고 test데이터를 예측한다.

<img src="/Users/jiwon/Library/Application Support/typora-user-images/스크린샷 2020-05-06 오후 8.10.42.png" alt="스크린샷 2020-05-06 오후 8.10.42" style="zoom:80%;" />

train 데이터와 마찬가지도 DataLoader를 통해 데이터를 불러오는데, 이 때 test 데이터는 평가하는 데이터이므로 shuffle을 사용하지 않고, shuffle을 사용하지 않으므로 x와 y를 묶을 (zip) 필요가 없다.

test 데이터를 학습된 모델을 통해 예측한다.



---



### 결과

<div style="display:flex;flex-flow:row nowrap;justify-content:space-around;">
	<div>
		<img src="/Users/jiwon/Library/Application Support/typora-user-images/스크린샷 2020-05-06 오전 1.51.24.png" alt="스크린샷 2020-05-06 오전 1.51.24" style="zoom:80%;" />
	</div>  
	<div>
		<img src="/Users/jiwon/Library/Application Support/typora-user-images/스크린샷 2020-05-06 오전 1.51.35.png" alt="스크린샷 2020-05-06 오전 1.51.35" style="zoom:80%;" />
	</div>
</div>
위는 에폭의 반복에 따라 각각 Loss값과 정확도를 표현한 그래프이다.


<div>
<img src="/Users/jiwon/Library/Application Support/typora-user-images/스크린샷 2020-05-06 오전 1.54.07.png" alt="스크린샷 2020-05-06 오전 1.54.07" style="zoom:80%;" />
<div>위 그래프의 정확한 수치는 다음과 같다</div>
</div>
##### 실행결과

![스크린샷 2020-05-06 오전 2.38.34](/Users/jiwon/Library/Application Support/typora-user-images/스크린샷 2020-05-06 오전 2.38.34.png)


