# Clustering

> k-means
>
> Hierarchical clustering
>
> DBSCAN (Density-based method)

## k-means

1. 처음 k를 사용자가 설정해주어야 한다.
2. 이 point가 각 centroid마다 얼마나 가까운지. 모든 점을 다 돌아서 k 개의 클러스터를 만든다.
3. 각 클러스터의 mean을 구하여 새로운 centroid로 설정한다.
4. centroid가 변경되지 않을 때까지 2~3을 반복한다.

##### `주의`

잘못된 centroid를 설정하면 영원히 좋은 결과값을 얻을 수 없다. 즉, centroid를 정하는 방법이 중요하다.

>  **centroid** : center point

##### Evaluation Clustering

SSE (Most common measure is Sum of Squared Error)

##### `단점`

- Sizes : 처음에 k개에 따라 결과가 엄청나게 달라진다. **k가 너무 중요하다.**
- Densities
- Non-globular shapes : sphere 형태만 가능하다.
- **outlier**에 취약하다.
  - 모든 점들은 하나의 cluster에 속하도록 강제되어있다.

## Hierarchical Clustering

최종 목표 : cluster가 하나가 될 때까지.

`2 main types`

- Agglomerative : 각각의 데이터부터 clustering한다.
- Divisive : 전체 하나의 cluster부터 나눈다.

##### Agglomerative

1. Compute the proximity matrix

##### `장점`

- k를 정할 필요가 없다.

##### max

`장점` : outlier에 덜 민감하다.

##### min

`장점`

## DBSCAN (Density-based method)

Eps : cluster의 반지름.

MinPts : min points. core point가 되기 위한 Eps 안에 있는 최소한의 point의 수.

- **core point** : 속하는 점

- **border point** : 경계에  있는 점

- **noise point** : core도, border도 아닌 점

1. 모든 점들을 핵심점, 경계점, 잡음점으로 표시한다.
2. 잡음점들을 제거한다
3. 서로간에 EPS의 거리 내에 있는 모든 핵심점들 사이에 간선을 만든다.
4. 각각의 연결된 핵심점들의 그룹을 독립적인 군집으로 만든다.
5. 각각의 경계점들을 관련된 핵심적의 군집들 중 하나에 속하게 한다.