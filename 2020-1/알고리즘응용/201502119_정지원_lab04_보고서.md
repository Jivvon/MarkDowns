# 201502119 정지원 lab04 보고서

### 데이터 전처리

seoul_student.txt에서 데이터를 추출하여 MinMax로 정규화하였다.

### Goal1 : 정규화하여 그래프 그리기

sklearn의 **MinMaxScalar()** 사용하여  정규화 후 그래프 그리기

<img src="/Users/jiwon/Library/Application Support/typora-user-images/스크린샷 2020-04-21 오후 3.12.02.png" alt="스크린샷 2020-04-21 오후 3.12.02" style="zoom:30%;" />

### Goal2 : sklearn pca활용하여 그래프 그리기

```python
pca = PCA(n_components=dim)
pca.fit(data)
X = pca.transform(data)
```

<img src="/Users/jiwon/Library/Application Support/typora-user-images/스크린샷 2020-04-21 오후 3.53.07.png" alt="스크린샷 2020-04-21 오후 3.53.07" style="zoom:30%;" />

<img src="/Users/jiwon/Library/Application Support/typora-user-images/스크린샷 2020-04-21 오후 4.06.00.png" alt="스크린샷 2020-04-21 오후 4.06.00" style="zoom:40%;" />

### Goal3 : 구현한 pca활용하여 그래프 그리기

<img src="/Users/jiwon/Library/Application Support/typora-user-images/스크린샷 2020-04-21 오후 10.00.54.png" alt="스크린샷 2020-04-21 오후 10.00.54" style="zoom:40%;" />

```python
def get_expected_value(values):
    # mean을 사용한 평균
    # expected_values = np.mean(values, axis=0)
    # ret = values - expected_values

    l = len(values)  # 데이터의 전체 길이
    mean_v = sum(values[:]) / l  # 각 열의 평균
    ret = values - mean_v  # expected value는 basis를 0으로 하기 위해 원래 데이터에서 평균을 뺀다

    return ret
```
expected value는 basis를 0으로 하기 위해 원래 데이터에서 평균을 뺀다

```python
def get_covariance_matrix(x, y, ex, ey):
    n = len(x)
    xx = sum((x-ex)*(x-ex))
    xy = sum((x-ex)*(y-ey))
    yy = sum((y-ey)*(y-ey))

    cov_mat = np.array([[xx, xy], [xy, yy]]) / n
    return cov_mat
```
공분산을 구한다 (2x2 행렬)

```python
e_val, e_vec = vals[dim-1], vecs[dim-1]
```
reduction 하고자하는 차원 -1 (여기선 1차원)의 고유벡터와 고유값


sklearn 라이브러리의 pca와 구현한 pca의 그래프를 비교해보면 축이 같지만 벡터의 방향이 정반대이므로 두 그래프가 좌우로 반전되어 나온다.








